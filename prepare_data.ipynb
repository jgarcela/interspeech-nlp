{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Interspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRANSCRIPTS = '/export/data_gpm/empatia/databases/MSP-podcast/Transcripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contenido del archivo MSP-PODCAST_2432_0200.txt:\n",
      "... happening there as well. and you have the black shirts and the brown shirts where the police either turned a blind eye or actively supported them, usually when they went on these rampages-\n",
      "\n",
      "Contenido del archivo MSP-PODCAST_0133_0033.txt:\n",
      " look they're - they're reporting on absolute admitted facts. ha-ha.\" \n",
      "\n",
      "Contenido del archivo MSP-PODCAST_0288_0019.txt:\n",
      "mr. [excess 00:01:24] also known as ike, bbc radio. download the bbc app. listen, share, and comment and whatever else [peel 00:01:29] says.\n",
      "\n",
      "Contenido del archivo MSP-PODCAST_2546_0333_0003.txt:\n",
      "and instead of us just handing people masks...\n",
      "\n",
      "Contenido del archivo MSP-PODCAST_3820_0101_0000.txt:\n",
      "or you're just done with all of the stuff that you've been doing, like system tuning.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def imprimir_contenido_txt(path, n):\n",
    "    # Verificar si el path existe\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"El path {path} no existe.\")\n",
    "        return\n",
    "    \n",
    "    # Listar archivos en el directorio que terminan con .txt\n",
    "    archivos = [f for f in os.listdir(path) if f.endswith('.txt')]\n",
    "    \n",
    "    # Si hay menos archivos que los solicitados, solo muestra los disponibles\n",
    "    archivos_a_mostrar = archivos[:n]\n",
    "    \n",
    "    if not archivos_a_mostrar:\n",
    "        print(\"No se encontraron archivos .txt.\")\n",
    "    else:\n",
    "        for archivo in archivos_a_mostrar:\n",
    "            print(f\"\\nContenido del archivo {archivo}:\")\n",
    "            archivo_path = os.path.join(path, archivo)\n",
    "            try:\n",
    "                with open(archivo_path, 'r') as f:\n",
    "                    print(f.read())  # Imprime el contenido del archivo\n",
    "            except Exception as e:\n",
    "                print(f\"Error al leer el archivo {archivo}: {e}\")\n",
    "\n",
    "imprimir_contenido_txt(PATH_TRANSCRIPTS, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando archivos:   1%|          | 939/116221 [00:09<20:14, 94.89archivo/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 51\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError al exportar el archivo CSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 51\u001b[0m df_txt \u001b[38;5;241m=\u001b[39m \u001b[43mcrear_dataframe_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_TRANSCRIPTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranscripts.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_txt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_txt\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# Muestra las primeras filas del DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mcrear_dataframe_txt\u001b[0;34m(path, output_csv)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(archivo_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     27\u001b[0m         nombres\u001b[38;5;241m.\u001b[39mappend(archivo)\n\u001b[0;32m---> 28\u001b[0m         textos\u001b[38;5;241m.\u001b[39mappend(\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Almacena el contenido del archivo\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError al leer el archivo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchivo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Importamos tqdm para la barra de progreso\n",
    "\n",
    "def crear_dataframe_txt(path, output_csv):\n",
    "    # Verificar si el path existe\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"El path {path} no existe.\")\n",
    "        return None\n",
    "    \n",
    "    # Listar archivos en el directorio que terminan con .txt\n",
    "    archivos = [f for f in os.listdir(path) if f.endswith('.txt')]\n",
    "    \n",
    "    if not archivos:\n",
    "        print(\"No se encontraron archivos .txt.\")\n",
    "        return None\n",
    "    \n",
    "    # Crear listas para almacenar los datos\n",
    "    nombres = []\n",
    "    textos = []\n",
    "    \n",
    "    # Recorrer los archivos .txt y leer su contenido con una barra de progreso\n",
    "    for i, archivo in enumerate(tqdm(archivos, desc=\"Procesando archivos\", unit=\"archivo\")):\n",
    "        archivo_path = os.path.join(path, archivo)\n",
    "        try:\n",
    "            with open(archivo_path, 'r') as f:\n",
    "                nombres.append(archivo)\n",
    "                textos.append(f.read())  # Almacena el contenido del archivo\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo {archivo}: {e}\")\n",
    "    \n",
    "    # Crear el DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'FileName': nombres,\n",
    "        'text': textos\n",
    "    })\n",
    "    \n",
    "    # Determinar el directorio del notebook y construir la ruta de salida\n",
    "    output_path = os.path.join(os.getcwd(), output_csv)\n",
    "\n",
    "    # Exportar el DataFrame a un archivo CSV\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Archivo CSV exportado exitosamente a: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al exportar el archivo CSV: {e}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df_txt = crear_dataframe_txt(PATH_TRANSCRIPTS, 'transcripts.csv')\n",
    "\n",
    "if df_txt is not None:\n",
    "    print(df_txt.head())  # Muestra las primeras filas del DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con .txt:\n",
      "                         FileName  \\\n",
      "0       MSP-PODCAST_2432_0200.txt   \n",
      "1       MSP-PODCAST_0133_0033.txt   \n",
      "2       MSP-PODCAST_0288_0019.txt   \n",
      "3  MSP-PODCAST_2546_0333_0003.txt   \n",
      "4  MSP-PODCAST_3820_0101_0000.txt   \n",
      "\n",
      "                                                text  \n",
      "0  ... happening there as well. and you have the ...  \n",
      "1   look they're - they're reporting on absolute ...  \n",
      "2  mr. [excess 00:01:24] also known as ike, bbc r...  \n",
      "3     and instead of us just handing people masks...  \n",
      "4  or you're just done with all of the stuff that...  \n",
      "DataFrame con .wav:\n",
      "                         FileName EmoClass  EmoAct  EmoVal  EmoDom  SpkrID  \\\n",
      "0       MSP-PODCAST_0133_0554.wav        C     5.0     2.8     5.2      54   \n",
      "1  MSP-PODCAST_1542_0059_0012.wav        N     3.2     4.0     4.8     804   \n",
      "2       MSP-PODCAST_3117_0573.wav        N     3.2     3.2     4.4    1519   \n",
      "3       MSP-PODCAST_2792_1031.wav        X     4.2     4.6     4.6     229   \n",
      "4  MSP-PODCAST_1353_0111_0001.wav        N     5.8     3.8     5.0     752   \n",
      "\n",
      "  Gender    Split_Set  PodcastID  StratifyCol NewPartition PseudoEmo  \\\n",
      "0   Male  Development        133    0133_54_C        Train         C   \n",
      "1   Male        Train       1542   1542_804_N        Train         N   \n",
      "2   Male        Train       3117  3117_1519_N        Train         N   \n",
      "3   Male        Train       2792   2792_229_X        Train         U   \n",
      "4   Male        Train       1353   1353_752_N        Train         N   \n",
      "\n",
      "   InvEntropyNorm  PseudoEmoNum  \n",
      "0        1.000000             4  \n",
      "1        1.000000             0  \n",
      "2        1.000000             0  \n",
      "3        0.267381             5  \n",
      "4        1.000000             0  \n",
      "DataFrame combinado:\n",
      "                     FileName  \\\n",
      "0       MSP-PODCAST_0288_0019   \n",
      "1  MSP-PODCAST_3371_0004_0001   \n",
      "2       MSP-PODCAST_0153_0436   \n",
      "3       MSP-PODCAST_2979_0216   \n",
      "4       MSP-PODCAST_0917_0196   \n",
      "\n",
      "                                                text EmoClass    EmoAct  \\\n",
      "0  mr. [excess 00:01:24] also known as ike, bbc r...        H  5.333333   \n",
      "1  ... i decided to take a trip to canada with my...        N  3.400000   \n",
      "2              just clowning in the studio, people.         H  5.777778   \n",
      "3  social distancing implies that we're being dis...        X  3.200000   \n",
      "4  ... in 2016. we won. okay. and our core messag...        N  4.800000   \n",
      "\n",
      "     EmoVal    EmoDom  SpkrID Gender    Split_Set  PodcastID  StratifyCol  \\\n",
      "0  5.416667  4.750000     123   Male        Train        288   0288_123_H   \n",
      "1  4.800000  4.200000    1769   Male  Development       3371  3371_1769_N   \n",
      "2  5.111111  5.444444      15   Male        Train        153    0153_15_H   \n",
      "3  4.000000  3.600000    1565   Male        Train       2979  2979_1565_X   \n",
      "4  3.600000  4.800000     266   Male        Train        917   0917_266_N   \n",
      "\n",
      "  NewPartition PseudoEmo  InvEntropyNorm  PseudoEmoNum  \n",
      "0        Train         H        1.000000             1  \n",
      "1   Evaluation         N        1.000000             0  \n",
      "2   Evaluation         H        1.000000             1  \n",
      "3   Evaluation         N        0.246159             0  \n",
      "4        Train         N        1.000000             0  \n"
     ]
    }
   ],
   "source": [
    "# Cargar el primer CSV (el que tiene los archivos .txt)\n",
    "df_txt = pd.read_csv('data/transcripts.csv')\n",
    "\n",
    "# Cargar el segundo CSV (el que tiene los archivos .wav)\n",
    "# df_wav = pd.read_csv('/export/data_gpm/empatia/databases/MSP-podcast/Labels/labels_consensus.csv')\n",
    "# df_wav = pd.read_csv('data/reduced_pseudo_female.csv')\n",
    "df_wav = pd.read_csv('data/reduced_pseudo_male.csv')\n",
    "\n",
    "# Mostrar las primeras filas de ambos DataFrames para ver la estructura\n",
    "print(\"DataFrame con .txt:\")\n",
    "print(df_txt.head())\n",
    "\n",
    "print(\"DataFrame con .wav:\")\n",
    "print(df_wav.head())\n",
    "\n",
    "# Eliminar la extensión '.txt' en el DataFrame con los archivos .txt\n",
    "df_txt['FileName'] = df_txt['FileName'].apply(lambda x: x.replace('.txt', ''))\n",
    "\n",
    "# Eliminar la extensión '.wav' en el DataFrame con los archivos .wav\n",
    "df_wav['FileName'] = df_wav['FileName'].apply(lambda x: x.replace('.wav', ''))\n",
    "\n",
    "# Realizar el merge de ambos DataFrames en la columna 'FileName'\n",
    "df_combinado = pd.merge(df_txt, df_wav, on='FileName', how='inner')  # 'inner' para solo coincidencias\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame combinado\n",
    "print(\"DataFrame combinado:\")\n",
    "print(df_combinado.head())\n",
    "\n",
    "# Exportar el DataFrame combinado a un archivo CSV\n",
    "# df_combinado.to_csv('data.csv', index=False)\n",
    "# df_combinado.to_csv('data/data_female.csv', index=False)\n",
    "df_combinado.to_csv('data/data_male.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_combinado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_male \u001b[38;5;241m=\u001b[39m \u001b[43mdf_combinado\u001b[49m[df_combinado[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m df_female \u001b[38;5;241m=\u001b[39m df_combinado[df_combinado[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFemale\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m df_male\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_male.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_combinado' is not defined"
     ]
    }
   ],
   "source": [
    "df_male = df_combinado[df_combinado['Gender'] == 'Male']\n",
    "df_female = df_combinado[df_combinado['Gender'] == 'Female']\n",
    "\n",
    "df_male.to_csv('data_male.csv', index=False)\n",
    "df_female.to_csv('data_female.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
