{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Interspeech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116221\n",
      "116193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>text</th>\n",
       "      <th>EmoClass</th>\n",
       "      <th>EmoAct</th>\n",
       "      <th>EmoVal</th>\n",
       "      <th>EmoDom</th>\n",
       "      <th>SpkrID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Split_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSP-PODCAST_2432_0200</td>\n",
       "      <td>... happening there as well. and you have the ...</td>\n",
       "      <td>S</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1425</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSP-PODCAST_0133_0033</td>\n",
       "      <td>look they're - they're reporting on absolute ...</td>\n",
       "      <td>D</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>6.60</td>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSP-PODCAST_0288_0019</td>\n",
       "      <td>mr. [excess 00:01:24] also known as ike, bbc r...</td>\n",
       "      <td>H</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>4.75</td>\n",
       "      <td>123</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSP-PODCAST_2546_0333_0003</td>\n",
       "      <td>and instead of us just handing people masks...</td>\n",
       "      <td>H</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1644</td>\n",
       "      <td>Male</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSP-PODCAST_3820_0101_0000</td>\n",
       "      <td>or you're just done with all of the stuff that...</td>\n",
       "      <td>N</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2289</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FileName  \\\n",
       "0       MSP-PODCAST_2432_0200   \n",
       "1       MSP-PODCAST_0133_0033   \n",
       "2       MSP-PODCAST_0288_0019   \n",
       "3  MSP-PODCAST_2546_0333_0003   \n",
       "4  MSP-PODCAST_3820_0101_0000   \n",
       "\n",
       "                                                text EmoClass    EmoAct  \\\n",
       "0  ... happening there as well. and you have the ...        S  2.800000   \n",
       "1   look they're - they're reporting on absolute ...        D  6.800000   \n",
       "2  mr. [excess 00:01:24] also known as ike, bbc r...        H  5.333333   \n",
       "3     and instead of us just handing people masks...        H  4.600000   \n",
       "4  or you're just done with all of the stuff that...        N  4.200000   \n",
       "\n",
       "     EmoVal  EmoDom  SpkrID  Gender    Split_Set  \n",
       "0  2.200000    3.40    1425    Male        Train  \n",
       "1  2.800000    6.60      54    Male  Development  \n",
       "2  5.416667    4.75     123    Male        Train  \n",
       "3  4.000000    4.80    1644    Male  Development  \n",
       "4  3.400000    4.40    2289  Female        Train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV\n",
    "data = pd.read_csv('data.csv')\n",
    "print(len(data))\n",
    "# Eliminar filas con valores nulos solo en la columna 'text'\n",
    "data = data.dropna(subset=['text'])\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto Train:\n",
      "                     FileName  \\\n",
      "0       MSP-PODCAST_2432_0200   \n",
      "2       MSP-PODCAST_0288_0019   \n",
      "4  MSP-PODCAST_3820_0101_0000   \n",
      "6       MSP-PODCAST_0545_0449   \n",
      "7       MSP-PODCAST_5492_2849   \n",
      "\n",
      "                                                text EmoClass    EmoAct  \\\n",
      "0  ... happening there as well. and you have the ...        S  2.800000   \n",
      "2  mr. [excess 00:01:24] also known as ike, bbc r...        H  5.333333   \n",
      "4  or you're just done with all of the stuff that...        N  4.200000   \n",
      "6  man, the power of contrast is so, i think, eas...        N  3.200000   \n",
      "7  ... we're older. so why not allow a little bit...        A  5.400000   \n",
      "\n",
      "     EmoVal  EmoDom  SpkrID  Gender Split_Set  \n",
      "0  2.200000    3.40    1425    Male     Train  \n",
      "2  5.416667    4.75     123    Male     Train  \n",
      "4  3.400000    4.40    2289  Female     Train  \n",
      "6  3.800000    3.80     227    Male     Train  \n",
      "7  2.400000    5.00    2889    Male     Train  \n",
      "Conjunto Development:\n",
      "                      FileName  \\\n",
      "1        MSP-PODCAST_0133_0033   \n",
      "3   MSP-PODCAST_2546_0333_0003   \n",
      "5   MSP-PODCAST_3371_0004_0001   \n",
      "14  MSP-PODCAST_1420_0011_0013   \n",
      "15       MSP-PODCAST_4707_0156   \n",
      "\n",
      "                                                 text EmoClass  EmoAct  \\\n",
      "1    look they're - they're reporting on absolute ...        D     6.8   \n",
      "3      and instead of us just handing people masks...        H     4.6   \n",
      "5   ... i decided to take a trip to canada with my...        N     3.4   \n",
      "14  and then she went on to found the coalition fo...        N     4.4   \n",
      "15  i really fucking want to do and it's been all ...        A     3.6   \n",
      "\n",
      "    EmoVal  EmoDom  SpkrID  Gender    Split_Set  \n",
      "1      2.8     6.6      54    Male  Development  \n",
      "3      4.0     4.8    1644    Male  Development  \n",
      "5      4.8     4.2    1769    Male  Development  \n",
      "14     4.2     5.0     772  Female  Development  \n",
      "15     3.4     3.6    2569  Female  Development  \n",
      "Conjunto Test:\n",
      "Empty DataFrame\n",
      "Columns: [FileName, text, EmoClass, EmoAct, EmoVal, EmoDom, SpkrID, Gender, Split_Set]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filtrar los datos en tres conjuntos basados en la columna 'Split_Set'\n",
    "train_df = data.loc[data['Split_Set'] == 'Train']\n",
    "dev_df = data.loc[data['Split_Set'] == 'Development']\n",
    "test_df = data.loc[data['Split_Set'] == 'Test']\n",
    "\n",
    "# Verifica las primeras filas de cada conjunto\n",
    "print(\"Conjunto Train:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"Conjunto Development:\")\n",
    "print(dev_df.head())\n",
    "\n",
    "print(\"Conjunto Test:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer la semilla para garantizar reproducibilidad\n",
    "seed = 42\n",
    "\n",
    "# Seleccionar aleatoriamente las primeras N filas del conjunto de entrenamiento\n",
    "train_df = train_df.sample(n=1000, random_state=seed)\n",
    "\n",
    "# Seleccionar aleatoriamente las primeras N filas del conjunto de desarrollo\n",
    "dev_df = dev_df.sample(n=250, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas únicas en 'EmoClass' antes del mapeo:\n",
      "['N' 'S' 'H' 'A' 'X' 'U' 'F' 'C' 'D' 'O']\n"
     ]
    }
   ],
   "source": [
    "# Verificar las etiquetas únicas en EmoClass antes de mapear\n",
    "print(\"Etiquetas únicas en 'EmoClass' antes del mapeo:\")\n",
    "print(train_df['EmoClass'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 10\n",
    "id2label = {\n",
    "    0: \"A\",\n",
    "    1: \"S\",\n",
    "    2: \"H\",\n",
    "    3: \"U\",\n",
    "    4: \"F\",\n",
    "    5: \"D\",\n",
    "    6: \"C\",\n",
    "    7: \"N\",\n",
    "    8: \"O\",\n",
    "    9: \"X\"\n",
    "}\n",
    "label2id = {\n",
    "    \"A\": 0,\n",
    "    \"S\": 1,\n",
    "    \"H\": 2,\n",
    "    \"U\": 3,\n",
    "    \"F\": 4,\n",
    "    \"D\": 5,\n",
    "    \"C\": 6,\n",
    "    \"N\": 7,\n",
    "    \"O\": 8,\n",
    "    \"X\": 9\n",
    "}\n",
    "\n",
    "# Convertir EmoClass a valores numéricos si es necesario\n",
    "train_df['EmoClass'] = train_df['EmoClass'].map(label2id).astype(int)\n",
    "dev_df['EmoClass'] = dev_df['EmoClass'].map(label2id).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Modelo\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "# Función para tokenizar los datos\n",
    "def tokenize_function(examples):\n",
    "    # Verificar que estamos pasando una lista de textos\n",
    "    texts = examples['text']\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Asegurarse de que 'train_df' y 'dev_df' son objetos Dataset de Hugging Face\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)\n",
    "\n",
    "# Tokenizamos ambos conjuntos de datos\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "dev_dataset = dev_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Renombrar columna de labels\n",
    "train_dataset = train_dataset.rename_column(\"EmoClass\", \"labels\")\n",
    "dev_dataset = dev_dataset.rename_column(\"EmoClass\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "print(torch.__version__)  # Esto debería mostrarte la versión de PyTorch instalada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels, id2label=id2label, label2id=label2id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Obtener reporte completo\n",
    "    report = classification_report(labels, predictions, output_dict=True)\n",
    "    \n",
    "    # Obtener la matriz de confusión\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    # Extraer métricas para cada clase y globales\n",
    "    metrics = {\n",
    "        'accuracy': report['accuracy'],\n",
    "        'weighted_f1': report['weighted avg']['f1-score'],\n",
    "        # 'weighted_precision': report['weighted avg']['precision'],\n",
    "        # 'weighted_recall': report['weighted avg']['recall'],\n",
    "        # La matriz de confusión no se incluye normalmente como una métrica devuelta porque no es un escalar\n",
    "        # 'confusion_matrix': conf_matrix.tolist()  # Convertir a lista para asegurarse de que es serializable si es necesario\n",
    "    }\n",
    "    \n",
    "    # # Añadir métricas específicas por clase si se requiere\n",
    "    # for label, scores in report.items():\n",
    "    #     if label not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "    #         metrics[f'{label}_precision'] = scores['precision']\n",
    "    #         metrics[f'{label}_recall'] = scores['recall']\n",
    "    #         metrics[f'{label}_f1'] = scores['f1-score']\n",
    "    #         metrics[f'{label}_support'] = scores['support']\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/dh/_ks73kfn57l67vxm7b5y16qw0000gn/T/ipykernel_29558/2523129008.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "logging_steps = len(train_dataset) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",       # Evalúa al final de cada epoch\n",
    "    save_strategy=\"epoch\",             # Guarda un checkpoint al final de cada epoch\n",
    "    save_total_limit=1,                # Mantiene solo el mejor checkpoint\n",
    "    load_best_model_at_end=True,       # Carga el mejor modelo al final del entrenamiento\n",
    "    metric_for_best_model=\"accuracy\",  # Métrica utilizada para seleccionar el mejor modelo\n",
    "    greater_is_better=True,            # Especifica si mayor valor es mejor para la métrica\n",
    "    logging_steps=logging_steps,\n",
    "    log_level=\"error\",\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 16:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.918700</td>\n",
       "      <td>1.914432</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.115489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.750400</td>\n",
       "      <td>1.872409</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.206577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.552600</td>\n",
       "      <td>1.886392</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.280479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.268500</td>\n",
       "      <td>2.050945</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.263589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.983200</td>\n",
       "      <td>2.150990</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.296491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.739300</td>\n",
       "      <td>2.376164</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.265352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>2.483486</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.260726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>2.617593</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.284329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>2.667080</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.275651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>2.734391</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.269500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=1.0015172088623048, metrics={'train_runtime': 1010.1109, 'train_samples_per_second': 9.9, 'train_steps_per_second': 1.237, 'total_flos': 1324862976000000.0, 'train_loss': 1.0015172088623048, 'epoch': 10.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgegarcelan/Desktop/UNI/6-LAB TSC/interspeech-nlp/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 2.734391450881958,\n",
       " 'test_accuracy': 0.284,\n",
       " 'test_weighted_f1': 0.2694996600208677,\n",
       " 'test_runtime': 7.87,\n",
       " 'test_samples_per_second': 31.766,\n",
       " 'test_steps_per_second': 4.066}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output = trainer.predict(dev_dataset)\n",
    "preds_output.metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
