{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Interspeech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116221\n",
      "116193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>text</th>\n",
       "      <th>EmoClass</th>\n",
       "      <th>EmoAct</th>\n",
       "      <th>EmoVal</th>\n",
       "      <th>EmoDom</th>\n",
       "      <th>SpkrID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Split_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSP-PODCAST_2432_0200</td>\n",
       "      <td>... happening there as well. and you have the ...</td>\n",
       "      <td>S</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1425</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSP-PODCAST_0133_0033</td>\n",
       "      <td>look they're - they're reporting on absolute ...</td>\n",
       "      <td>D</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>6.60</td>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSP-PODCAST_0288_0019</td>\n",
       "      <td>mr. [excess 00:01:24] also known as ike, bbc r...</td>\n",
       "      <td>H</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>4.75</td>\n",
       "      <td>123</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSP-PODCAST_2546_0333_0003</td>\n",
       "      <td>and instead of us just handing people masks...</td>\n",
       "      <td>H</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1644</td>\n",
       "      <td>Male</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSP-PODCAST_3820_0101_0000</td>\n",
       "      <td>or you're just done with all of the stuff that...</td>\n",
       "      <td>N</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2289</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FileName  \\\n",
       "0       MSP-PODCAST_2432_0200   \n",
       "1       MSP-PODCAST_0133_0033   \n",
       "2       MSP-PODCAST_0288_0019   \n",
       "3  MSP-PODCAST_2546_0333_0003   \n",
       "4  MSP-PODCAST_3820_0101_0000   \n",
       "\n",
       "                                                text EmoClass    EmoAct  \\\n",
       "0  ... happening there as well. and you have the ...        S  2.800000   \n",
       "1   look they're - they're reporting on absolute ...        D  6.800000   \n",
       "2  mr. [excess 00:01:24] also known as ike, bbc r...        H  5.333333   \n",
       "3     and instead of us just handing people masks...        H  4.600000   \n",
       "4  or you're just done with all of the stuff that...        N  4.200000   \n",
       "\n",
       "     EmoVal  EmoDom  SpkrID  Gender    Split_Set  \n",
       "0  2.200000    3.40    1425    Male        Train  \n",
       "1  2.800000    6.60      54    Male  Development  \n",
       "2  5.416667    4.75     123    Male        Train  \n",
       "3  4.000000    4.80    1644    Male  Development  \n",
       "4  3.400000    4.40    2289  Female        Train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV\n",
    "data = pd.read_csv('data.csv')\n",
    "print(len(data))\n",
    "# Eliminar filas con valores nulos solo en la columna 'text'\n",
    "data = data.dropna(subset=['text'])\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto Train:\n",
      "                     FileName  \\\n",
      "0       MSP-PODCAST_2432_0200   \n",
      "2       MSP-PODCAST_0288_0019   \n",
      "4  MSP-PODCAST_3820_0101_0000   \n",
      "6       MSP-PODCAST_0545_0449   \n",
      "7       MSP-PODCAST_5492_2849   \n",
      "\n",
      "                                                text EmoClass    EmoAct  \\\n",
      "0  ... happening there as well. and you have the ...        S  2.800000   \n",
      "2  mr. [excess 00:01:24] also known as ike, bbc r...        H  5.333333   \n",
      "4  or you're just done with all of the stuff that...        N  4.200000   \n",
      "6  man, the power of contrast is so, i think, eas...        N  3.200000   \n",
      "7  ... we're older. so why not allow a little bit...        A  5.400000   \n",
      "\n",
      "     EmoVal  EmoDom  SpkrID  Gender Split_Set  \n",
      "0  2.200000    3.40    1425    Male     Train  \n",
      "2  5.416667    4.75     123    Male     Train  \n",
      "4  3.400000    4.40    2289  Female     Train  \n",
      "6  3.800000    3.80     227    Male     Train  \n",
      "7  2.400000    5.00    2889    Male     Train  \n",
      "Conjunto Development:\n",
      "                      FileName  \\\n",
      "1        MSP-PODCAST_0133_0033   \n",
      "3   MSP-PODCAST_2546_0333_0003   \n",
      "5   MSP-PODCAST_3371_0004_0001   \n",
      "14  MSP-PODCAST_1420_0011_0013   \n",
      "15       MSP-PODCAST_4707_0156   \n",
      "\n",
      "                                                 text EmoClass  EmoAct  \\\n",
      "1    look they're - they're reporting on absolute ...        D     6.8   \n",
      "3      and instead of us just handing people masks...        H     4.6   \n",
      "5   ... i decided to take a trip to canada with my...        N     3.4   \n",
      "14  and then she went on to found the coalition fo...        N     4.4   \n",
      "15  i really fucking want to do and it's been all ...        A     3.6   \n",
      "\n",
      "    EmoVal  EmoDom  SpkrID  Gender    Split_Set  \n",
      "1      2.8     6.6      54    Male  Development  \n",
      "3      4.0     4.8    1644    Male  Development  \n",
      "5      4.8     4.2    1769    Male  Development  \n",
      "14     4.2     5.0     772  Female  Development  \n",
      "15     3.4     3.6    2569  Female  Development  \n",
      "Conjunto Test:\n",
      "Empty DataFrame\n",
      "Columns: [FileName, text, EmoClass, EmoAct, EmoVal, EmoDom, SpkrID, Gender, Split_Set]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filtrar los datos en tres conjuntos basados en la columna 'Split_Set'\n",
    "train_df = data.loc[data['Split_Set'] == 'Train']\n",
    "dev_df = data.loc[data['Split_Set'] == 'Development']\n",
    "test_df = data.loc[data['Split_Set'] == 'Test']\n",
    "\n",
    "# Verifica las primeras filas de cada conjunto\n",
    "print(\"Conjunto Train:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"Conjunto Development:\")\n",
    "print(dev_df.head())\n",
    "\n",
    "print(\"Conjunto Test:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las primeras 1000 filas de los datos de entrenamiento y desarrollo\n",
    "train_df = train_df.head(1000)  # Primeros 1000 ejemplos del conjunto de entrenamiento\n",
    "dev_df = dev_df.head(250)  # Primeros 1000 ejemplos del conjunto de desarrollo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas √∫nicas en 'EmoClass' antes del mapeo:\n",
      "['S' 'H' 'N' 'A' 'X' 'C' 'U' 'O' 'D' 'F']\n"
     ]
    }
   ],
   "source": [
    "# Verificar las etiquetas √∫nicas en EmoClass antes de mapear\n",
    "print(\"Etiquetas √∫nicas en 'EmoClass' antes del mapeo:\")\n",
    "print(train_df['EmoClass'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 10\n",
    "id2label = {\n",
    "    0: \"A\",\n",
    "    1: \"S\",\n",
    "    2: \"H\",\n",
    "    3: \"U\",\n",
    "    4: \"F\",\n",
    "    5: \"D\",\n",
    "    6: \"C\",\n",
    "    7: \"N\",\n",
    "    8: \"O\",\n",
    "    9: \"X\"\n",
    "}\n",
    "label2id = {\n",
    "    \"A\": 0,\n",
    "    \"S\": 1,\n",
    "    \"H\": 2,\n",
    "    \"U\": 3,\n",
    "    \"F\": 4,\n",
    "    \"D\": 5,\n",
    "    \"C\": 6,\n",
    "    \"N\": 7,\n",
    "    \"O\": 8,\n",
    "    \"X\": 9\n",
    "}\n",
    "\n",
    "# Convertir EmoClass a valores num√©ricos si es necesario\n",
    "train_df['EmoClass'] = train_df['EmoClass'].map(label2id).astype(int)\n",
    "dev_df['EmoClass'] = dev_df['EmoClass'].map(label2id).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jggomez/Desktop/IRIS/Interspeech/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 4540.77 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 6750.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Modelo\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "# Funci√≥n para tokenizar los datos\n",
    "def tokenize_function(examples):\n",
    "    # Verificar que estamos pasando una lista de textos\n",
    "    texts = examples['text']\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Asegurarse de que 'train_df' y 'dev_df' son objetos Dataset de Hugging Face\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)\n",
    "\n",
    "# Tokenizamos ambos conjuntos de datos\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "dev_dataset = dev_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Renombrar columna de labels\n",
    "train_dataset = train_dataset.rename_column(\"EmoClass\", \"labels\")\n",
    "dev_dataset = dev_dataset.rename_column(\"EmoClass\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "print(torch.__version__)  # Esto deber√≠a mostrarte la versi√≥n de PyTorch instalada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jggomez/Desktop/IRIS/Interspeech/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels, id2label=id2label, label2id=label2id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # Desempaquetamos las predicciones y las etiquetas\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Convertimos logits a etiquetas predichas usando argmax\n",
    "    predictions = torch.argmax(torch.tensor(logits), axis=-1)\n",
    "\n",
    "    # Calculamos precisi√≥n\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Calculamos F1 score (micro promedio)\n",
    "    f1 = f1_score(labels, predictions, average='micro')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jggomez/Desktop/IRIS/Interspeech/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1854650/2636174946.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "logging_steps = len(train_dataset) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    #push_to_hub=True,\n",
    "    log_level=\"error\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 27:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.161500</td>\n",
       "      <td>2.099988</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>2.051714</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.237000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=32, training_loss=2.045714110136032, metrics={'train_runtime': 1718.8558, 'train_samples_per_second': 1.164, 'train_steps_per_second': 0.019, 'total_flos': 264972595200000.0, 'train_loss': 2.045714110136032, 'epoch': 2.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 2.0517144203186035,\n",
       " 'test_accuracy': 0.237,\n",
       " 'test_f1': 0.237,\n",
       " 'test_runtime': 155067.0275,\n",
       " 'test_samples_per_second': 0.006,\n",
       " 'test_steps_per_second': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output = trainer.predict(dev_dataset)\n",
    "preds_output.metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
